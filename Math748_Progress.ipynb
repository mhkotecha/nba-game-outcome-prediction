{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d1cfcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patron\\AppData\\Local\\Temp\\ipykernel_24608\\1780211015.py:10: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  games_details = pd.read_csv('C:/Users/patron/Desktop/MATH 748/NBA Data/games_details.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Games Dataset:\n",
      "(26651, 21)\n",
      "  GAME_DATE_EST   GAME_ID GAME_STATUS_TEXT  HOME_TEAM_ID  VISITOR_TEAM_ID  \\\n",
      "0    2022-12-22  22200477            Final    1610612740       1610612759   \n",
      "1    2022-12-22  22200478            Final    1610612762       1610612764   \n",
      "2    2022-12-21  22200466            Final    1610612739       1610612749   \n",
      "3    2022-12-21  22200467            Final    1610612755       1610612765   \n",
      "4    2022-12-21  22200468            Final    1610612737       1610612741   \n",
      "\n",
      "   SEASON  TEAM_ID_home  PTS_home  FG_PCT_home  FT_PCT_home  ...  AST_home  \\\n",
      "0    2022    1610612740     126.0        0.484        0.926  ...      25.0   \n",
      "1    2022    1610612762     120.0        0.488        0.952  ...      16.0   \n",
      "2    2022    1610612739     114.0        0.482        0.786  ...      22.0   \n",
      "3    2022    1610612755     113.0        0.441        0.909  ...      27.0   \n",
      "4    2022    1610612737     108.0        0.429        1.000  ...      22.0   \n",
      "\n",
      "   REB_home  TEAM_ID_away  PTS_away  FG_PCT_away  FT_PCT_away  FG3_PCT_away  \\\n",
      "0      46.0    1610612759     117.0        0.478        0.815         0.321   \n",
      "1      40.0    1610612764     112.0        0.561        0.765         0.333   \n",
      "2      37.0    1610612749     106.0        0.470        0.682         0.433   \n",
      "3      49.0    1610612765      93.0        0.392        0.735         0.261   \n",
      "4      47.0    1610612741     110.0        0.500        0.773         0.292   \n",
      "\n",
      "   AST_away  REB_away  HOME_TEAM_WINS  \n",
      "0      23.0      44.0               1  \n",
      "1      20.0      37.0               1  \n",
      "2      20.0      46.0               1  \n",
      "3      15.0      46.0               1  \n",
      "4      20.0      47.0               0  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "\n",
      "Games Details Dataset:\n",
      "(668628, 29)\n",
      "    GAME_ID     TEAM_ID TEAM_ABBREVIATION    TEAM_CITY  PLAYER_ID  \\\n",
      "0  22200477  1610612759               SAS  San Antonio    1629641   \n",
      "1  22200477  1610612759               SAS  San Antonio    1631110   \n",
      "2  22200477  1610612759               SAS  San Antonio    1627751   \n",
      "3  22200477  1610612759               SAS  San Antonio    1630170   \n",
      "4  22200477  1610612759               SAS  San Antonio    1630200   \n",
      "\n",
      "      PLAYER_NAME NICKNAME START_POSITION COMMENT    MIN  ...  OREB  DREB  \\\n",
      "0  Romeo Langford    Romeo              F     NaN  18:06  ...   1.0   1.0   \n",
      "1   Jeremy Sochan   Jeremy              F     NaN  31:01  ...   6.0   3.0   \n",
      "2    Jakob Poeltl    Jakob              C     NaN  21:42  ...   1.0   3.0   \n",
      "3   Devin Vassell    Devin              G     NaN  30:20  ...   0.0   9.0   \n",
      "4       Tre Jones      Tre              G     NaN  27:44  ...   0.0   2.0   \n",
      "\n",
      "   REB  AST  STL  BLK   TO   PF   PTS  PLUS_MINUS  \n",
      "0  2.0  0.0  1.0  0.0  2.0  5.0   2.0        -2.0  \n",
      "1  9.0  6.0  1.0  0.0  2.0  1.0  23.0       -14.0  \n",
      "2  4.0  1.0  1.0  0.0  2.0  4.0  13.0        -4.0  \n",
      "3  9.0  5.0  3.0  0.0  2.0  1.0  10.0       -18.0  \n",
      "4  2.0  3.0  0.0  0.0  2.0  2.0  19.0         0.0  \n",
      "\n",
      "[5 rows x 29 columns]\n",
      "\n",
      "Players Dataset:\n",
      "(7228, 4)\n",
      "        PLAYER_NAME     TEAM_ID  PLAYER_ID  SEASON\n",
      "0     Royce O'Neale  1610612762    1626220    2019\n",
      "1  Bojan Bogdanovic  1610612762     202711    2019\n",
      "2       Rudy Gobert  1610612762     203497    2019\n",
      "3  Donovan Mitchell  1610612762    1628378    2019\n",
      "4       Mike Conley  1610612762     201144    2019\n",
      "\n",
      "Ranking Dataset:\n",
      "(210342, 13)\n",
      "      TEAM_ID  LEAGUE_ID  SEASON_ID STANDINGSDATE CONFERENCE         TEAM   G  \\\n",
      "0  1610612743          0      22022    2022-12-22       West       Denver  30   \n",
      "1  1610612763          0      22022    2022-12-22       West      Memphis  30   \n",
      "2  1610612740          0      22022    2022-12-22       West  New Orleans  31   \n",
      "3  1610612756          0      22022    2022-12-22       West      Phoenix  32   \n",
      "4  1610612746          0      22022    2022-12-22       West  LA Clippers  33   \n",
      "\n",
      "    W   L  W_PCT HOME_RECORD ROAD_RECORD  RETURNTOPLAY  \n",
      "0  19  11  0.633        10-3         9-8           NaN  \n",
      "1  19  11  0.633        13-2         6-9           NaN  \n",
      "2  19  12  0.613        13-4         6-8           NaN  \n",
      "3  19  13  0.594        14-4         5-9           NaN  \n",
      "4  19  14  0.576        11-7         8-7           NaN  \n",
      "\n",
      "Missing Values in Games Dataset:\n",
      "GAME_DATE_EST        0\n",
      "GAME_ID              0\n",
      "GAME_STATUS_TEXT     0\n",
      "HOME_TEAM_ID         0\n",
      "VISITOR_TEAM_ID      0\n",
      "SEASON               0\n",
      "TEAM_ID_home         0\n",
      "PTS_home            99\n",
      "FG_PCT_home         99\n",
      "FT_PCT_home         99\n",
      "FG3_PCT_home        99\n",
      "AST_home            99\n",
      "REB_home            99\n",
      "TEAM_ID_away         0\n",
      "PTS_away            99\n",
      "FG_PCT_away         99\n",
      "FT_PCT_away         99\n",
      "FG3_PCT_away        99\n",
      "AST_away            99\n",
      "REB_away            99\n",
      "HOME_TEAM_WINS       0\n",
      "dtype: int64\n",
      "\n",
      "Missing Values in Games Details Dataset:\n",
      "GAME_ID                   0\n",
      "TEAM_ID                   0\n",
      "TEAM_ABBREVIATION         0\n",
      "TEAM_CITY                 0\n",
      "PLAYER_ID                 0\n",
      "PLAYER_NAME               0\n",
      "NICKNAME             615591\n",
      "START_POSITION       412863\n",
      "COMMENT              558939\n",
      "MIN                  109690\n",
      "FGM                  109690\n",
      "FGA                  109690\n",
      "FG_PCT               109690\n",
      "FG3M                 109690\n",
      "FG3A                 109690\n",
      "FG3_PCT              109690\n",
      "FTM                  109690\n",
      "FTA                  109690\n",
      "FT_PCT               109690\n",
      "OREB                 109690\n",
      "DREB                 109690\n",
      "REB                  109690\n",
      "AST                  109690\n",
      "STL                  109690\n",
      "BLK                  109690\n",
      "TO                   109690\n",
      "PF                   109690\n",
      "PTS                  109690\n",
      "PLUS_MINUS           133351\n",
      "dtype: int64\n",
      "\n",
      "Missing Values in Players Dataset:\n",
      "PLAYER_NAME    0\n",
      "TEAM_ID        0\n",
      "PLAYER_ID      0\n",
      "SEASON         0\n",
      "dtype: int64\n",
      "\n",
      "Missing Values in Ranking Dataset:\n",
      "TEAM_ID               0\n",
      "LEAGUE_ID             0\n",
      "SEASON_ID             0\n",
      "STANDINGSDATE         0\n",
      "CONFERENCE            0\n",
      "TEAM                  0\n",
      "G                     0\n",
      "W                     0\n",
      "L                     0\n",
      "W_PCT                 0\n",
      "HOME_RECORD           0\n",
      "ROAD_RECORD           0\n",
      "RETURNTOPLAY     206352\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Importing the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Loading the datasets\n",
    "games = pd.read_csv('C:/Users/patron/Desktop/MATH 748/NBA Data/games.csv')\n",
    "games_details = pd.read_csv('C:/Users/patron/Desktop/MATH 748/NBA Data/games_details.csv')\n",
    "players = pd.read_csv('C:/Users/patron/Desktop/MATH 748/NBA Data/players.csv')\n",
    "ranking = pd.read_csv('C:/Users/patron/Desktop/MATH 748/NBA Data/ranking.csv')\n",
    "\n",
    "# Basic exploration to check the shape and first few rows of each dataset\n",
    "print(\"Games Dataset:\")\n",
    "print(games.shape)\n",
    "print(games.head())\n",
    "\n",
    "print(\"\\nGames Details Dataset:\")\n",
    "print(games_details.shape)\n",
    "print(games_details.head())\n",
    "\n",
    "print(\"\\nPlayers Dataset:\")\n",
    "print(players.shape)\n",
    "print(players.head())\n",
    "\n",
    "print(\"\\nRanking Dataset:\")\n",
    "print(ranking.shape)\n",
    "print(ranking.head())\n",
    "\n",
    "# Checking for missing values in each dataset\n",
    "print(\"\\nMissing Values in Games Dataset:\")\n",
    "print(games.isnull().sum())\n",
    "\n",
    "print(\"\\nMissing Values in Games Details Dataset:\")\n",
    "print(games_details.isnull().sum())\n",
    "\n",
    "print(\"\\nMissing Values in Players Dataset:\")\n",
    "print(players.isnull().sum())\n",
    "\n",
    "print(\"\\nMissing Values in Ranking Dataset:\")\n",
    "print(ranking.isnull().sum())\n",
    "\n",
    "# Handling any missing values\n",
    "games_details_cleaned = games_details.dropna()\n",
    "games_details_cleaned = games_details.fillna(games_details.mean())\n",
    "\n",
    "# Feature selection\n",
    "games_selected = games.drop(columns=['GAME_ID', 'GAME_STATUS_TEXT'])\n",
    "games_details_selected = games_details.drop(columns=['PLAYER_ID', 'NICKNAME', 'COMMENT'])\n",
    "\n",
    "# Encoding the categorical variables\n",
    "games_details_selected['TEAM_ABBREVIATION'] = games_details_selected['TEAM_ABBREVIATION'].astype('category').cat.codes\n",
    "\n",
    "# Scaling some of the features\n",
    "scaler = StandardScaler()\n",
    "games_selected[['PTS_home', 'PTS_away', 'REB_home', 'REB_away']] = scaler.fit_transform(\n",
    "    games_selected[['PTS_home', 'PTS_away', 'REB_home', 'REB_away']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9864818e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7c38b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating summary statistics for key features in the games dataset\n",
    "print(\"\\nSummary statistics for Games dataset:\")\n",
    "print(games_selected[['PTS_home', 'PTS_away', 'FG_PCT_home', 'FG_PCT_away', 'REB_home', 'REB_away']].describe())\n",
    "\n",
    "# Visualizing the distributions of key features using histograms\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Histogram for points scored by home teams\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(games_selected['PTS_home'], kde=True, color='blue')\n",
    "plt.title('Distribution of Points for Home Teams')\n",
    "\n",
    "# Histogram for points scored by away teams\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(games_selected['PTS_away'], kde=True, color='green')\n",
    "plt.title('Distribution of Points for Away Teams')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Step 12: Boxplots for comparing performance of home vs away teams\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Boxplot for home and away points\n",
    "sns.boxplot(data=games_selected[['PTS_home', 'PTS_away']])\n",
    "plt.title('Boxplot Comparison of Home and Away Points')\n",
    "plt.ylabel('Points')\n",
    "plt.xticks([0, 1], ['Home Points', 'Away Points'])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Correlation heatmap to identify relationships between features\n",
    "plt.figure(figsize=(10, 8))\n",
    "corr_matrix = games_selected[['PTS_home', 'PTS_away', 'FG_PCT_home', 'FG_PCT_away', 'REB_home', 'REB_away']].corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.title('Correlation Matrix of Key Game Features')\n",
    "plt.show()\n",
    "\n",
    "# Analyzing win distributions (home vs away)\n",
    "win_counts = games_selected['HOME_TEAM_WINS'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.barplot(x=win_counts.index, y=win_counts.values, palette='Set2')\n",
    "plt.title('Home vs Away Wins')\n",
    "plt.xticks([0, 1], ['Away Wins', 'Home Wins'])\n",
    "plt.ylabel('Number of Games')\n",
    "plt.show()\n",
    "\n",
    "# Trend analysis over season by season \n",
    "seasonal_points = games_selected.groupby('SEASON')[['PTS_home', 'PTS_away']].mean()\n",
    "\n",
    "# Plotting the trend of points over seasons\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(seasonal_points.index, seasonal_points['PTS_home'], label='Home Points', marker='o', color='blue')\n",
    "plt.plot(seasonal_points.index, seasonal_points['PTS_away'], label='Away Points', marker='o', color='green')\n",
    "plt.title('Average Points per Game for Home and Away Teams Over Seasons')\n",
    "plt.xlabel('Season')\n",
    "plt.ylabel('Average Points')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8c3cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "from sklearn.feature_selection import VarianceThreshold, RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load preprocessed dataset\n",
    "X = games_cleaned.drop(columns=['HOME_TEAM_WINS'])  # Features\n",
    "y = games_cleaned['HOME_TEAM_WINS']  # Target variable (win/loss)\n",
    "\n",
    "# Step 1: Correlation Analysis\n",
    "plt.figure(figsize=(10, 8))\n",
    "corr_matrix = X.corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()\n",
    "\n",
    "# Step 2: Variance Thresholding\n",
    "# Remove low-variance features\n",
    "variance_selector = VarianceThreshold(threshold=0.01)\n",
    "X_high_variance = variance_selector.fit_transform(X)\n",
    "\n",
    "print(\"Number of features after variance thresholding:\", X_high_variance.shape[1])\n",
    "\n",
    "# Step 3: Recursive Feature Elimination (RFE)\n",
    "# Use Logistic Regression for RFE\n",
    "logreg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "rfe_selector = RFE(logreg, n_features_to_select=5, step=1)  # Selecting the top 5 features\n",
    "X_rfe = rfe_selector.fit_transform(X_high_variance, y)\n",
    "\n",
    "# Print selected features\n",
    "selected_features = X.columns[variance_selector.get_support()][rfe_selector.get_support()]\n",
    "print(\"Top 10 selected features:\", list(selected_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfa02d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, mean_absolute_error, mean_squared_error\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Data splitting\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_rfe, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Logistic Regression\n",
    "logreg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred_logreg = logreg.predict(X_test)\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred_logreg))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_logreg))\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf_params = {'n_estimators': [50, 100, 200], 'max_depth': [None, 10, 20]}\n",
    "rf_grid = GridSearchCV(rf, rf_params, cv=5, scoring='accuracy')\n",
    "rf_grid.fit(X_train, y_train)\n",
    "y_pred_rf = rf_grid.best_estimator_.predict(X_test)\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_rf))\n",
    "\n",
    "# Gradient Boosting\n",
    "gb = GradientBoostingClassifier(random_state=42)\n",
    "gb_params = {'n_estimators': [50, 100, 200], 'learning_rate': [0.01, 0.1, 0.2]}\n",
    "gb_grid = GridSearchCV(gb, gb_params, cv=5, scoring='accuracy')\n",
    "gb_grid.fit(X_train, y_train)\n",
    "y_pred_gb = gb_grid.best_estimator_.predict(X_test)\n",
    "print(\"Gradient Boosting Accuracy:\", accuracy_score(y_test, y_pred_gb))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_gb))\n",
    "\n",
    "# Linear Regression for Point Margin Prediction\n",
    "y_margin = games_cleaned['PTS_home'] - games_cleaned['PTS_away']\n",
    "X_train_margin, X_test_margin, y_train_margin, y_test_margin = train_test_split(X_rfe, y_margin, test_size=0.3, random_state=42)\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train_margin, y_train_margin)\n",
    "y_pred_margin = linreg.predict(X_test_margin)\n",
    "print(\"Linear Regression MAE:\", mean_absolute_error(y_test_margin, y_pred_margin))\n",
    "print(\"Linear Regression RMSE:\", np.sqrt(mean_squared_error(y_test_margin, y_pred_margin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e714494",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assume `games_cleaned` is the preprocessed dataset from earlier steps\n",
    "\n",
    "# Adding contextual features\n",
    "games_cleaned['Home_Win_Streak'] = games_cleaned.groupby('HOME_TEAM_ID')['HOME_TEAM_WINS'].cumsum().shift(1).fillna(0)\n",
    "games_cleaned['Away_Win_Streak'] = games_cleaned.groupby('VISITOR_TEAM_ID')['HOME_TEAM_WINS'].apply(lambda x: (~x).cumsum().shift(1).fillna(0))\n",
    "\n",
    "# Assuming 'SEASON' column exists to calculate Rest Days\n",
    "games_cleaned['Rest_Days_Home'] = games_cleaned.groupby('HOME_TEAM_ID')['GAME_DATE_EST'].diff().dt.days.fillna(7)\n",
    "games_cleaned['Rest_Days_Away'] = games_cleaned.groupby('VISITOR_TEAM_ID')['GAME_DATE_EST'].diff().dt.days.fillna(7)\n",
    "\n",
    "# Adding advanced basketball metrics\n",
    "# Effective Field Goal Percentage (eFG%)\n",
    "games_cleaned['eFG_PCT_home'] = (games_cleaned['FG_PCT_home'] + 0.5 * games_cleaned['FG3_PCT_home']).fillna(0)\n",
    "games_cleaned['eFG_PCT_away'] = (games_cleaned['FG_PCT_away'] + 0.5 * games_cleaned['FG3_PCT_away']).fillna(0)\n",
    "\n",
    "# Player Efficiency Rating (PER)\n",
    "# Using a simplified formula: PER = (PTS + AST + REB + STL + BLK) - (FGA - FGM) - TO\n",
    "games_cleaned['PER_home'] = (\n",
    "    games_cleaned['PTS_home'] + games_cleaned['AST_home'] + games_cleaned['REB_home'] +\n",
    "    games_cleaned['STL_home'] + games_cleaned['BLK_home'] -\n",
    "    (games_cleaned['FGA_home'] - games_cleaned['FGM_home']) - games_cleaned['TO_home']\n",
    ").fillna(0)\n",
    "\n",
    "games_cleaned['PER_away'] = (\n",
    "    games_cleaned['PTS_away'] + games_cleaned['AST_away'] + games_cleaned['REB_away'] +\n",
    "    games_cleaned['STL_away'] + games_cleaned['BLK_away'] -\n",
    "    (games_cleaned['FGA_away'] - games_cleaned['FGM_away']) - games_cleaned['TO_away']\n",
    ").fillna(0)\n",
    "\n",
    "# Display the updated dataset's head to verify changes\n",
    "print(games_cleaned[['Home_Win_Streak', 'Away_Win_Streak', 'Rest_Days_Home', 'Rest_Days_Away', 'eFG_PCT_home', 'eFG_PCT_away', 'PER_home', 'PER_away']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded47990",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Setting up the visualization style\n",
    "sns.set(style=\"whitegrid\", palette=\"muted\", color_codes=True)\n",
    "\n",
    "# 1. Distribution of Home and Away Win Streaks\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(games_cleaned['Home_Win_Streak'], kde=True, color='blue', label='Home Win Streak')\n",
    "sns.histplot(games_cleaned['Away_Win_Streak'], kde=True, color='green', label='Away Win Streak')\n",
    "plt.title('Distribution of Home and Away Win Streaks')\n",
    "plt.xlabel('Win Streak')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 2. Boxplot of Rest Days (Home vs. Away Teams)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=games_cleaned[['Rest_Days_Home', 'Rest_Days_Away']], orient='h')\n",
    "plt.title('Boxplot of Rest Days for Home and Away Teams')\n",
    "plt.yticks([0, 1], ['Home Rest Days', 'Away Rest Days'])\n",
    "plt.xlabel('Days')\n",
    "plt.show()\n",
    "\n",
    "# 3. Scatter Plot: Effective Field Goal Percentage (eFG%) vs. Points Scored\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.scatterplot(x=games_cleaned['eFG_PCT_home'], y=games_cleaned['PTS_home'], label='Home', color='blue')\n",
    "sns.scatterplot(x=games_cleaned['eFG_PCT_away'], y=games_cleaned['PTS_away'], label='Away', color='green')\n",
    "plt.title('Effective Field Goal Percentage (eFG%) vs. Points Scored')\n",
    "plt.xlabel('eFG%')\n",
    "plt.ylabel('Points Scored')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 4. Violin Plot: Player Efficiency Rating (PER) vs. Home Team Wins\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.violinplot(x=games_cleaned['HOME_TEAM_WINS'], y=games_cleaned['PER_home'], palette='Set2')\n",
    "plt.title('Player Efficiency Rating (PER) by Home Team Wins')\n",
    "plt.xlabel('Home Team Wins (0 = Loss, 1 = Win)')\n",
    "plt.ylabel('PER (Home Team)')\n",
    "plt.show()\n",
    "\n",
    "# 5. Heatmap: Correlations of New Features with Game Outcomes\n",
    "plt.figure(figsize=(10, 8))\n",
    "new_features = ['Home_Win_Streak', 'Away_Win_Streak', 'Rest_Days_Home', 'Rest_Days_Away', 'eFG_PCT_home', 'eFG_PCT_away', 'PER_home', 'PER_away', 'HOME_TEAM_WINS']\n",
    "corr_matrix = games_cleaned[new_features].corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.title('Correlation Heatmap of New Features with Game Outcomes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eadd602",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Splitting the data\n",
    "X = games_cleaned.drop(columns=['HOME_TEAM_WINS'])  # Features\n",
    "y = games_cleaned['HOME_TEAM_WINS']  # Target variable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 1. XGBoost Classifier\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "xgb_params = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2]\n",
    "}\n",
    "xgb_grid = GridSearchCV(xgb_model, xgb_params, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "xgb_grid.fit(X_train, y_train)\n",
    "xgb_best = xgb_grid.best_estimator_\n",
    "y_pred_xgb = xgb_best.predict(X_test)\n",
    "\n",
    "print(\"XGBoost Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_xgb))\n",
    "\n",
    "# 2. LightGBM Classifier\n",
    "lgb_model = lgb.LGBMClassifier(random_state=42)\n",
    "lgb_params = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2]\n",
    "}\n",
    "lgb_grid = GridSearchCV(lgb_model, lgb_params, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "lgb_grid.fit(X_train, y_train)\n",
    "lgb_best = lgb_grid.best_estimator_\n",
    "y_pred_lgb = lgb_best.predict(X_test)\n",
    "\n",
    "print(\"LightGBM Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_lgb))\n",
    "\n",
    "# 3. CatBoost Classifier\n",
    "cat_model = CatBoostClassifier(verbose=0, random_state=42)\n",
    "cat_params = {\n",
    "    'iterations': [50, 100, 200],\n",
    "    'depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2]\n",
    "}\n",
    "cat_grid = GridSearchCV(cat_model, cat_params, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "cat_grid.fit(X_train, y_train)\n",
    "cat_best = cat_grid.best_estimator_\n",
    "y_pred_cat = cat_best.predict(X_test)\n",
    "\n",
    "print(\"CatBoost Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_cat))\n",
    "\n",
    "# Comparing Accuracy Scores\n",
    "xgb_acc = accuracy_score(y_test, y_pred_xgb)\n",
    "lgb_acc = accuracy_score(y_test, y_pred_lgb)\n",
    "cat_acc = accuracy_score(y_test, y_pred_cat)\n",
    "\n",
    "print(f\"XGBoost Accuracy: {xgb_acc:.4f}\")\n",
    "print(f\"LightGBM Accuracy: {lgb_acc:.4f}\")\n",
    "print(f\"CatBoost Accuracy: {cat_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6797e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Target variable: Point margin\n",
    "y_margin = games_cleaned['PTS_home'] - games_cleaned['PTS_away']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_margin, test_size=0.3, random_state=42)\n",
    "\n",
    "# 1. Random Forest Regression\n",
    "rf_reg = RandomForestRegressor(random_state=42)\n",
    "rf_params = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20]\n",
    "}\n",
    "rf_grid = GridSearchCV(rf_reg, rf_params, cv=5, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "rf_grid.fit(X_train, y_train)\n",
    "rf_best = rf_grid.best_estimator_\n",
    "y_pred_rf = rf_best.predict(X_test)\n",
    "\n",
    "# Random Forest Metrics\n",
    "rf_mae = mean_absolute_error(y_test, y_pred_rf)\n",
    "rf_rmse = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
    "print(f\"Random Forest MAE: {rf_mae:.4f}, RMSE: {rf_rmse:.4f}\")\n",
    "\n",
    "# 2. Gradient Boosting Regression\n",
    "gb_reg = GradientBoostingRegressor(random_state=42)\n",
    "gb_params = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "gb_grid = GridSearchCV(gb_reg, gb_params, cv=5, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "gb_grid.fit(X_train, y_train)\n",
    "gb_best = gb_grid.best_estimator_\n",
    "y_pred_gb = gb_best.predict(X_test)\n",
    "\n",
    "# Gradient Boosting Metrics\n",
    "gb_mae = mean_absolute_error(y_test, y_pred_gb)\n",
    "gb_rmse = np.sqrt(mean_squared_error(y_test, y_pred_gb))\n",
    "print(f\"Gradient Boosting MAE: {gb_mae:.4f}, RMSE: {gb_rmse:.4f}\")\n",
    "\n",
    "# 3. XGBoost Regression\n",
    "xgb_reg = XGBRegressor(random_state=42)\n",
    "xgb_params = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "xgb_grid = GridSearchCV(xgb_reg, xgb_params, cv=5, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "xgb_grid.fit(X_train, y_train)\n",
    "xgb_best = xgb_grid.best_estimator_\n",
    "y_pred_xgb = xgb_best.predict(X_test)\n",
    "\n",
    "# XGBoost Metrics\n",
    "xgb_mae = mean_absolute_error(y_test, y_pred_xgb)\n",
    "xgb_rmse = np.sqrt(mean_squared_error(y_test, y_pred_xgb))\n",
    "print(f\"XGBoost MAE: {xgb_mae:.4f}, RMSE: {xgb_rmse:.4f}\")\n",
    "\n",
    "# Comparing Regression Models\n",
    "print(\"\\nRegression Model Performance:\")\n",
    "print(f\"Random Forest: MAE = {rf_mae:.4f}, RMSE = {rf_rmse:.4f}\")\n",
    "print(f\"Gradient Boosting: MAE = {gb_mae:.4f}, RMSE = {gb_rmse:.4f}\")\n",
    "print(f\"XGBoost: MAE = {xgb_mae:.4f}, RMSE = {xgb_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f55d6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Splitting the dataset\n",
    "X = games_cleaned.drop(columns=['HOME_TEAM_WINS'])  # Features\n",
    "y = games_cleaned['HOME_TEAM_WINS']  # Target variable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Applying SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"Class distribution after SMOTE:\")\n",
    "print(y_train_smote.value_counts())\n",
    "\n",
    "# Retraining Models on Balanced Data\n",
    "\n",
    "# 1. Logistic Regression\n",
    "logreg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "logreg.fit(X_train_smote, y_train_smote)\n",
    "y_pred_logreg = logreg.predict(X_test)\n",
    "print(\"\\nLogistic Regression After SMOTE:\")\n",
    "print(classification_report(y_test, y_pred_logreg))\n",
    "\n",
    "# 2. Random Forest\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train_smote, y_train_smote)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "print(\"\\nRandom Forest After SMOTE:\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "\n",
    "# 3. Gradient Boosting\n",
    "gb = GradientBoostingClassifier(random_state=42)\n",
    "gb.fit(X_train_smote, y_train_smote)\n",
    "y_pred_gb = gb.predict(X_test)\n",
    "print(\"\\nGradient Boosting After SMOTE:\")\n",
    "print(classification_report(y_test, y_pred_gb))\n",
    "\n",
    "# Comparing Accuracy Scores\n",
    "logreg_acc = accuracy_score(y_test, y_pred_logreg)\n",
    "rf_acc = accuracy_score(y_test, y_pred_rf)\n",
    "gb_acc = accuracy_score(y_test, y_pred_gb)\n",
    "\n",
    "print(\"\\nModel Accuracy After SMOTE:\")\n",
    "print(f\"Logistic Regression: {logreg_acc:.4f}\")\n",
    "print(f\"Random Forest: {rf_acc:.4f}\")\n",
    "print(f\"Gradient Boosting: {gb_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dafa703",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming `recent_games` contains recent game data for testing\n",
    "# Ensure recent_games is preprocessed the same way as the training dataset\n",
    "\n",
    "# Prepare the recent games dataset\n",
    "X_recent = recent_games.drop(columns=['HOME_TEAM_WINS', 'PTS_home', 'PTS_away'])  # Features\n",
    "y_recent_class = recent_games['HOME_TEAM_WINS']  # Actual outcomes for classification\n",
    "y_recent_margin = recent_games['PTS_home'] - recent_games['PTS_away']  # Actual margins for regression\n",
    "\n",
    "# Classification Predictions\n",
    "# Using the best model (e.g., Gradient Boosting from earlier)\n",
    "y_pred_class = gb_best.predict(X_recent)\n",
    "\n",
    "# Regression Predictions\n",
    "# Using the best regression model (e.g., XGBoost Regression)\n",
    "y_pred_margin = xgb_best.predict(X_recent)\n",
    "\n",
    "# Evaluate Classification Predictions\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "print(\"Classification Report on Recent Games:\")\n",
    "print(classification_report(y_recent_class, y_pred_class))\n",
    "\n",
    "accuracy_recent = accuracy_score(y_recent_class, y_pred_class)\n",
    "print(f\"Accuracy on Recent Games: {accuracy_recent:.4f}\")\n",
    "\n",
    "# Evaluate Regression Predictions\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "mae_recent = mean_absolute_error(y_recent_margin, y_pred_margin)\n",
    "rmse_recent = np.sqrt(mean_squared_error(y_recent_margin, y_pred_margin))\n",
    "\n",
    "print(\"\\nRegression Metrics on Recent Games:\")\n",
    "print(f\"Mean Absolute Error: {mae_recent:.4f}\")\n",
    "print(f\"Root Mean Square Error: {rmse_recent:.4f}\")\n",
    "\n",
    "# Compare Actual vs Predicted\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Actual_Outcome': y_recent_class,\n",
    "    'Predicted_Outcome': y_pred_class,\n",
    "    'Actual_Margin': y_recent_margin,\n",
    "    'Predicted_Margin': y_pred_margin\n",
    "})\n",
    "print(\"\\nComparison of Actual vs Predicted:\")\n",
    "print(comparison_df.head(10))  # Display first 10 comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b7b9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding win streak features\n",
    "games_cleaned['Home_Win_Streak'] = games_cleaned.groupby('HOME_TEAM_ID')['HOME_TEAM_WINS'].cumsum().shift(1).fillna(0)\n",
    "games_cleaned['Away_Win_Streak'] = games_cleaned.groupby('VISITOR_TEAM_ID')['HOME_TEAM_WINS'].apply(lambda x: (~x).cumsum().shift(1).fillna(0))\n",
    "\n",
    "# Adding rest days features\n",
    "games_cleaned['Rest_Days_Home'] = games_cleaned.groupby('HOME_TEAM_ID')['GAME_DATE_EST'].diff().dt.days.fillna(7)\n",
    "games_cleaned['Rest_Days_Away'] = games_cleaned.groupby('VISITOR_TEAM_ID')['GAME_DATE_EST'].diff().dt.days.fillna(7)\n",
    "\n",
    "# Effective Field Goal Percentage (eFG%)\n",
    "games_cleaned['eFG_PCT_home'] = (games_cleaned['FG_PCT_home'] + 0.5 * games_cleaned['FG3_PCT_home']).fillna(0)\n",
    "games_cleaned['eFG_PCT_away'] = (games_cleaned['FG_PCT_away'] + 0.5 * games_cleaned['FG3_PCT_away']).fillna(0)\n",
    "\n",
    "# Player Efficiency Rating (PER)\n",
    "games_cleaned['PER_home'] = (\n",
    "    games_cleaned['PTS_home'] + games_cleaned['AST_home'] + games_cleaned['REB_home'] +\n",
    "    games_cleaned['STL_home'] + games_cleaned['BLK_home'] -\n",
    "    (games_cleaned['FGA_home'] - games_cleaned['FGM_home']) - games_cleaned['TO_home']\n",
    ").fillna(0)\n",
    "\n",
    "games_cleaned['PER_away'] = (\n",
    "    games_cleaned['PTS_away'] + games_cleaned['AST_away'] + games_cleaned['REB_away'] +\n",
    "    games_cleaned['STL_away'] + games_cleaned['BLK_away'] -\n",
    "    (games_cleaned['FGA_away'] - games_cleaned['FGM_away']) - games_cleaned['TO_away']\n",
    ").fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e424a92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting outcomes and margins for recent games\n",
    "y_pred_class_recent = xgb_best.predict(X_recent)  # Classification\n",
    "y_pred_margin_recent = xgb_best.predict(X_recent)  # Regression\n",
    "\n",
    "# Comparing predictions with actual results\n",
    "comparison = pd.DataFrame({\n",
    "    'Actual Outcome': y_recent_class,\n",
    "    'Predicted Outcome': y_pred_class_recent,\n",
    "    'Actual Margin': y_recent_margin,\n",
    "    'Predicted Margin': y_pred_margin_recent\n",
    "})\n",
    "print(comparison.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
